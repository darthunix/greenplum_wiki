# Выделение памяти запросу

Выделение памяти для запроса происходит на этапе его выполнения в функции **execMain.c->ExecutorStart** в зависимости от политики выделения памяти:
  * Auto
  * Eager Free (по-умолчанию)

## Eager Free

Входной точкой для выделения памяти является функция **memquota.c->PolicyEagerFreeAssignOperatorMemoryKB**, которая принимает на вход план запроса и количество доступной для запроса памяти. Основная задача данной функции - создать дерево операторов на основе дерева плана и каждому узлу дерева выделить нужное ему количество памяти.

**Важный момент!** В GP на мастере строится не только план, но и каждому узлу плана выделяется размер памяти для исполнения. При этом память раздается с учетом доступной GP памяти на мастере и если ее больше, чем на сегментах, то это может приводить к ошибкам вида `Resource group memory limit reached`, так как построенный план с выделенными кусками памяти для каждого узла дерева плана отправляется на сегменты без изменений. В этом можно убедиться в **execMain.c->ExecutorStart**, где выделение памяти производится в блоке кода `Gp_role == GP_ROLE_DISPATCH`. Посмотреть выделенные куски памяти можно, выставив в сессии `set gp_resgroup_print_operator_memory_limits=on;`. **Как следствие, памяти на мастере должно быть такое же количество, как и на хостах сегментов.**

Поэтому, перед тем, как рассматривать распределение памяти по узлам дерева, посмотрим, откуда берется вообще память для запроса. За это отвечает функция **memquota.c->ResourceManagerGetQueryMemoryLimit**.

### ResourceManagerGetQueryMemoryLimit

Данная функция является оберткой над другими функциями в зависимости от того, используются ли ресурсные очереди или ресурсные группы. Так как у нас используются ресурсные группы, то вся логика получения памяти находится в функции **resgroup.c->ResourceGroupGetQueryMemoryLimit**.

Память в ресурсной группе выделяется кусками и запрос при старте получает:
```
((rgNum * memory_spill_ratio / 100) / concurrency) << chunk_size_in_bits
```

  * rgNum - кол-во кусков памяти ресурсной группы
  * memory_spill_ratio - одноименный GUC
  * concurrency - количество слотов в ресурсной группе для одновременного исполнения
  * chunk_size_in_bits - размер куска памяти (обычно по 1МБ)

Если //memory_spill_ratio = 0//, то память выделяется в размере //statement_mem// в обход стандартного механизма выделения памяти.

Именно это количество памяти мы передадим с планом запроса в функцию **PolicyEagerFreeAssignOperatorMemoryKB**.

Общее количество памяти, доступное GP, рассчитывается в функции **resgroup-ops-linux.c->ResGroupOps_GetTotalMemory**. Оно определяется минимальным значением между `swap + ram * overcommitRatio / 100` и `ram + swap`, доступными с учетом cgroups.


### PolicyEagerFreeAssignOperatorMemoryKB

Особенностью данной политики (в отличие от устаревшей Auto) является учет того факта, что не все узлы плана будут выполняться одновременно и поэтому можно выделять на каждый узел, осуществляющий ресурсоемкие операции, больше памяти.

Операции являются ресурсоемкими, если они из списка:
  * Material
  * Sort
  * ShareInputScan
  * Hash
  * BitmapIndexScan
  * WindowAgg
  * TableFunctionScan
  * FunctionScan
  * Agg (для хеш, distinct и сортированных агрегаций)
  * Result

Логика функции следующая
  - На основе дерева плана запроса мы строим дерево операторов с помощью функции PolicyEagerFreePrelimWalker(оказывается, в ГП есть фреймворк для обхода деревьев в walkers.c). Пока в каждом узле дерева есть только информация о том, сколько ниже по трассе лежит ресурсоемких и нересурсоемких узлов (и для сколько из них могут исполняться одновременно). Информации о количестве доступной памяти на узел еще нет, это нужно получить далее.
  - Проверяем, что выделенной памяти хватит на выполнение запроса с помощью функции autoIncOpMemForResGroup. При этом если не хватает, мы говорим "все узлы плана по 100КБ" и заменяем значение выделенной нам памяти на этот минимум (все узлы * 100КБ). Если упадем с ООМ, то такова судьба...
  - Начинаем проставлять каждому узлу дерева операторов необходимую ему память с помощью **memquota.c->PolicyEagerFreeAssignWalker**, по факту являющейся оберткой над **memquota.c->ComputeMemLimitForChildGroups**

### ComputeMemLimitForChildGroups

Для каждого узла дерева операторов мы уже знаем, сколько в его дочерних узлах:
  * ресурсоемких узлов
  * одновременно выполняемых ресурсоемких узлов
  * нересурсоемких узлов
  * одновременно выполняемых нересурсоемких узлов

Задача функции обойти дерево ресурсов и каждому узлу выделить кусок памяти из общей памяти запроса.
  - Считаем для каждого родительского узла количество ресурсоемких и нересурсоемких узлов (//max(узлы, параллельные узлы)//)
  - Для каждого узла родителя:
    * Проверяем, что в родительском узле хватает памяти хотя бы на нересурсоемкие узлы (иначе ошибка insufficient memory reserved for statement)
    * Если есть дочерние ресурсоемкие узлы, то раздаем память вначале нересурсоемким (им всегда по 100КБ), а осташуюся память пропорционально делим между ресурсоемкими узлами (пропорционально в зависимости от количества ресурсоемких операций в дочерних узлах)
